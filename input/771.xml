<xMetaDiss:xMetaDiss xmlns:xMetaDiss="http://www.d-nb.de/standards/xmetadissplus/" xmlns:cc="http://www.d-nb.de/standards/cc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcmitype="http://purl.org/dc/dcmitype/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:pc="http://www.d-nb.de/standards/pc/" xmlns:urn="http://www.d-nb.de/standards/urn/" xmlns:hdl="http://www.d-nb.de/standards/hdl/" xmlns:doi="http://www.d-nb.de/standards/doi/" xmlns:thesis="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:ddb="http://www.d-nb.de/standards/ddb/" xmlns:dini="http://www.d-nb.de/standards/xmetadissplus/type/" xmlns="http://www.d-nb.de/standards/subject/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:doc="http://www.lyncode.com/xoai" xsi:schemaLocation="http://www.d-nb.de/standards/xmetadissplus/  http://files.dnb.de/standards/xmetadissplus/xmetadissplus.xsd"><id>771</id>
   <dc:title xsi:type="ddb:titleISO639-2" lang="eng">Auditory image understanding for the visually impaired based on a modular computer vision sonification model</dc:title>
   <dc:title xsi:type="ddb:titleISO639-2" lang="ger">Akustisches Bildverständnis für Sehbehinderte basierend auf einem modularen Computer Visions Sonifikations Modell</dc:title>
   <dc:creator xsi:type="pc:MetaPers">
      <pc:person>
         <pc:name type="nameUsedByThePerson">
            <pc:foreName>Michael</pc:foreName>
            <pc:surName>Banf</pc:surName>
         </pc:name>
      </pc:person>
   </dc:creator>
   <dc:subject xsi:type="xMetaDiss:noScheme">Computer Vision</dc:subject>
   <dc:subject xsi:type="xMetaDiss:noScheme">Sonifikation</dc:subject>
   <dc:subject xsi:type="xMetaDiss:noScheme">Computer Mensch Interaktion</dc:subject>
   <dc:subject xsi:type="xMetaDiss:noScheme">Assistive Systeme</dc:subject>
   <dc:subject xsi:type="xMetaDiss:DDC-SG">004</dc:subject>
   <dcterms:abstract xsi:type="ddb:contentISO639-2" lang="ger">Die vorliegende Arbeit beschreibt ein System das blinden Menschen einen direkt erfahrbaren Zugang zu Bildern mit Hilfe akustischer Signale anbietet. Der Benutzer exploriert ein Bild interaktiv auf einem berührungsempfindlichen Bildschirm und erhält eine akustische Rückmeldung über den Bildinhalt an der jeweiligen Fingerposition. Die Gestaltung eines solchen Systems beinhaltet zwei größere Herausforderungen: Welche ist die relevante Bildinformation, und wie kann möglichst viel Information in einem Audiosignal untergebracht werden. Wir behandeln diese Probleme basierend auf einem modularen Computer Vision Sonikations Modell, welches wir als grundlegendes Gerüst für die Aufnahme,&#13;
Exploration und Sonikation von visueller Information zur Unterstützung blinder Menschen vorstellen. Es werden einige Ansätze vorgestellt, welche hierzu die Information auf verschiedenen Abstraktionsebenen kombinieren. So z.B. sehr grundlegende Information wie Farbe, Kanten und Rauigkeit und komplexere Information welche durch die Verwendung von Machine Learning Algorithmen gewonnen werden kann. Diese Machine Learning Algorithmen behandeln sowohl das Erkennen von Objekten als auch die Klassikation von Bildregionen in "künstlich" und "natürlich", basierend auf einem neu entwickelten Typs eines probabilistischen graphischen Modells. Wir zeigen, dass dieser Mehr-Ebenen Ansatz dem Benutzer direkten Zugang zum Wesen und Position von Objekten und Strukturen im Bild ermöglicht und gleichzeitig das Potential neuester Entwicklungen im Bereich Computer Vision und Machine Learning ausnutzt. Während der Exploration kann der Benutzer erkannte "künstliche" Strukturen oder bestimmte natürliche Regionen als Referenzpunkte verwenden um andere natürliche Regionen mit Hilfe deren individueller Position, Farbe und Texturen zu klassizieren. Wir werden zeigen, dass geburtsblinde Teilnehmer diese Strategie erfolgreich einsetzen um ganze Szenen zu interpretieren und zu verstehen.</dcterms:abstract>
   <dcterms:abstract xsi:type="ddb:contentISO639-2" lang="eng">This thesis presents a system that strives to give visually impaired people direct perceptual access to images via an acoustic signal. The user explores the image actively on a touch screen or touch pad and receives auditory feedback about the image content at the current position. The design of such a system involves two major challenges: what is the most useful and relevant image information, and how can as much information as possible be captured in an audio signal. We address those problems, based on a Modular Computer Vision Sonication Model, which we propose as a general framework for acquisition, exploration and sonication of visual information to support visually impaired people. General approaches are presented that combine low-level information, such as color, edges, and roughness, with mid- and high-level information obtained from Machine Learning algorithms. This includes object recognition and the classication of regions into the categories "man-made" versus "natural" based on a novel type of discriminative graphical model. We argue that this multi-level approach gives users direct access to the identity and location of objects and structures in the image, yet it still exploits the potential of recent developments in Computer Vision and Machine Learning. During exploration, the user can utilize detected man made structures or specic natural regions as reference points to classify other natural regions by their individual location, color and texture. We show that congenital blind participants employ that strategy successfully to interpret and understand whole scenes.</dcterms:abstract>
   <dc:publisher xsi:type="cc:Publisher" type="dcterms:ISO3166" countryCode="DE">
      <cc:universityOrInstitution cc:GKD-Nr="509551-7">
         <cc:name>Universitätsbibliothek der Universität Siegen</cc:name>
         <cc:place>Siegen</cc:place>
      </cc:universityOrInstitution>
      <cc:address cc:Scheme="DIN5008">Adolf-Reichweinstr. 2, 57068 Siegen</cc:address>
   </dc:publisher>
   <dcterms:dateAccepted xsi:type="dcterms:W3CDTF">2013-10-15</dcterms:dateAccepted>
   <dcterms:issued xsi:type="dcterms:W3CDTF">2013</dcterms:issued>
   <dc:type xsi:type="dini:PublType">doctoralThesis</dc:type>
   <dc:type xsi:type="dcterms:DCMIType">Text</dc:type>
   <dini:version_driver>publishedVersion</dini:version_driver>
   <dc:identifier xsi:type="urn:nbn">urn:nbn:de:hbz:467-7716</dc:identifier>
   <dc:language xsi:type="dcterms:ISO639-2">eng</dc:language>
   <dc:rights xsi:type="dcterms:URI">https://dspace.ub.uni-siegen.de/static/license.txt</dc:rights>
   <thesis:degree>
      <thesis:level>thesis.doctoral</thesis:level>
      <thesis:grantor xsi:type="cc:Corporate" type="dcterms:ISO3166" countryCode="DE">
         <cc:universityOrInstitution>
            <cc:name>Universität Siegen</cc:name>
            <cc:place>Siegen</cc:place>
            <cc:department>
               <cc:name>Institut für Bildinformatik</cc:name>
               <cc:place>Siegen</cc:place>
            </cc:department>
         </cc:universityOrInstitution>
      </thesis:grantor>
   </thesis:degree>
   <ddb:contact ddb:contactID="L6000-0732"/>
   <ddb:fileNumber>1</ddb:fileNumber>
   <ddb:fileProperties ddb:fileName="banf.pdf" ddb:fileSize="45638791"/>
   <ddb:checksum ddb:type="MD5">e6b4eb30cbade6e442e5aed4c2089f38</ddb:checksum>
   <ddb:transfer ddb:type="dcterms:URI">https://dspace.ub.uni-siegen.de/bitstream/ubsi/771/1/banf.pdf</ddb:transfer>
   <ddb:identifier ddb:type="URL">https://dspace.ub.uni-siegen.de/handle/ubsi/771</ddb:identifier>
   <ddb:rights ddb:kind="free"/>
   <ddb:server>Universitätsbibliothek Siegen</ddb:server>
</xMetaDiss:xMetaDiss>